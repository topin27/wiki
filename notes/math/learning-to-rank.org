* 缘起

基本检索模型中，用来排序所考虑的因素并不多，由人工进行公式拟合是完全可行的。随着搜索引擎的发展，对于网页进行排序需要考虑的因素增多，比如PageRank值、查询和文档匹配的单词个数、网页url链接地址的长度等都对网页排名有影响。

其中标注的数据来源主要是依靠用户点击。

* 几个思想

PointWise和PairWise把排序问题转换成回归、分类或有序分类问题，ListWise把Query下整个搜索结果作为一个训练的实例。三种方法主要体现在损失函数的不同。

** PointWise

将文档根据是否相关构造成数据集，形如：

| docid       | queryid   | feature1   | feature2   | ...   | featureN   | 相关性   |
|-------------+-----------+------------+------------+-------+------------+----------|
| 苹果 电脑   | 0.19      | 8          | 2          | ...   | 2          | 相关     |

然后训练各个feature的权重。

** PairWise

PointWise没有考虑文档之间的顺序关系。在推荐领域，被推荐的事物分为两类，一类是被用户点击，另一类是未被点击，在排序时，如果将后者放在了前者的前面，这生成了一个错误的排序对，对应着一条训练数据X。而X的长度为主题的个数
。

但是仍然存在两个问题：

-  排序对只考虑了两个文档的相对先后顺序，如果前列文档出现判断错误，代价明显高于排在后面的文档；
-  不同的查询，其相关排序对的数量差异较大，所以在样本中容易出现偏斜问题，造成排序对较少的查询错误率即使较高，也不能太大影响整体的错误率，导致继续调优困难。

** ListWise

ListWise
中，一个查询及其对应的所有搜索结果评分作为一个实例。根据这些训练实例得到最优评分函数(F)，对于一个新的用户查询，函数(F)对每一个文档进行打分，按照得分高低进行排序。

训练方式为：假设有3篇文档ABC，评分函数F会分别得出相关性分数F(A),F(B),F(C)，根据这3个得分可以计算6中不同的排列组合情况各自的概率值，不同的评分函数，6中搜索结果的排列组合的概率分布(F')是不一样的。假设有一个理想的评分函数G，其概率分布为(G')，那么训练的目标就是寻找和(G')最相似的(F')，通过KL距离可以衡量初两个概率分布差异的大小。

*** KL距离

KL距离（Kullback-Leibler
Divergence），也叫相对熵，用于衡量相同事件空间里的两个概率分布的差异情况。其物理意义是：在相同的事件空间中，概率分布P(X)对应的每个事件，若用概率分布Q(X)编码时，平均每个基本事件编码长度增加了多少比特。计算公式如下：
[D(P||Q)=\sum/{x{\in}X}{P(x)log\frac{P(x)}{Q(x)}}]
当概率分布相同时，相对熵为0。其中概率分布(P(X)的信息熵为：
[H(P)=-\sum/{x{\in}X}{P(x){log}P(x)}]
其表示概率分布P(X)编码时，平均每个基本事件至少需要多少比特。因此不存在其他比按照概率分布更好的编码方式了。

* 具体算法

** RankNet

* 参考

-  [[http://www.cnblogs.com/kemaswill/archive/2013/06/01/3109497.html][Learning
   to Rank 简介]]
-  [[https://tech.meituan.com/deep_learning_doc.html][深度学习在文本领域的应用
   -- 美团算法团队]]
-  [[https://baijiahao.baidu.com/s?id=1570247207721372][百度NLP |
   神经网络语义匹配技术]]
-  [[https://blog.csdn.net/eastmount/article/details/43080791][【学习排序】
   Learning to
   Rank中Pointwise关于PRank算法源码实现]]：其中清楚描述了样本集的形式
-  [[https://blog.csdn.net/eastmount/article/details/42367515][机器学习排序之Learning
   to Rank简单介绍]]
